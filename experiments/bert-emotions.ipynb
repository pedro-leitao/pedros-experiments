{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a BERT model for Classification\n",
    "\n",
    "Fine-tuning a [BERT](https://huggingface.co/docs/transformers/en/model_doc/bert) (Bidirectional Encoder Representations from Transformers) model for classification tasks involves adapting this pre-trained model to perform specific text classification tasks. Here’s a straightforward introduction to the concept.\n",
    "\n",
    "BERT is a type of transformer model that was pre-trained on a large corpus of text. It uses a mechanism known as [attention](https://arxiv.org/abs/1706.03762), allowing the model to weigh the importance of different words relative to others for a better understanding of context. This model was designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and sentiment analysis, without substantial modifications.\n",
    "\n",
    "The [Transformers library](https://huggingface.co/docs/transformers/en/index), provides a collection of pre-trained models like BERT, GPT (Generative Pre-trained Transformer), and others for Natural Language Processing (NLP). The library offers APIs to easily import and use these models. Both BERT and GPT are based on the transformer architecture but serve different purposes; BERT is designed to refine the understanding of sentence context and relations, making it ideal for classification tasks. In contrast, GPT is oriented towards generating text based on the input given.\n",
    "\n",
    "Fine-tuning BERT for classification involves:\n",
    "1. **Initializing BERT with pre-trained weights**: These weights have learned underlying patterns in language from its training dataset, typically datasets like Wikipedia.\n",
    "2. **Adding a classification layer**: This layer will make predictions based on the representations from BERT.\n",
    "3. **Training the model on a specific dataset**: This step adapts BERT’s weights slightly to the nuances of the classification task at hand, without losing the generalized understanding it has developed.\n",
    "\n",
    "This process customizes BERT to effectively perform on specific classification tasks by leveraging both its pre-trained general understanding of language and its capacity to adapt to particular contexts.\n",
    "\n",
    "Let's start with a very simple classification example, where we will fine-tune a pre-trained BERT model to classify text into a set of emotion classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow and Transformers library\n",
    "\n",
    "For context, here are the versions of TensorFlow, the Transformers library and TensorFlow-Metal used in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.16.1\n",
      "Transformers Version: 4.39.3\n",
      "tensorflow-metal              1.1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import tensorflow as tf\n",
    "from transformers import __version__ as transformers_version\n",
    "\n",
    "# Print TensorFlow and Keras version\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# Print Transformers (Hugging Face BERT) version\n",
    "print(\"Transformers Version:\", transformers_version)\n",
    "\n",
    "!pip list | grep tensorflow-metal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We will use the [Emotion Dataset](https://huggingface.co/datasets/emotion) from the Hugging Face datasets library. This dataset contains text samples labeled with one of six emotions: sadness, joy, love, anger, fear and surprise. We will use this dataset to fine-tune a pre-trained BERT model for text classification. In this case we will use the `kaggle` library to download the dataset directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/nelgiriyewithana/emotions\n",
      "License(s): other\n",
      "Downloading emotions.zip to .data\n",
      " 96%|████████████████████████████████████▎ | 15.0M/15.7M [00:02<00:00, 8.81MB/s]\n",
      "100%|██████████████████████████████████████| 15.7M/15.7M [00:02<00:00, 7.10MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0      i just feel really helpless and heavy hearted      4\n",
       "1  ive enjoyed being able to slouch about relax a...      0\n",
       "2  i gave up my internship with the dmrg and am f...      4\n",
       "3                         i dont know i feel so lost      0\n",
       "4  i am a kindergarten teacher and i am thoroughl...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download dataset\n",
    "!kaggle datasets download -d nelgiriyewithana/emotions -p .data/ --unzip\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('.data/text.csv')\n",
    "\n",
    "# Drop the first column\n",
    "data = data.drop(data.columns[0], axis='columns')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let us take a look at the shape of the dataframe - as expected it has 6 target classes, and is composed of just over 400K samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416809, 2)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(data.shape)\n",
    "\n",
    "# And let us count the number of unique categories\n",
    "n_categories = data['label'].nunique()\n",
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels have the following meanings:\n",
    "\n",
    "- 0: Sadness\n",
    "- 1: Joy\n",
    "- 2: Love\n",
    "- 3: Anger\n",
    "- 4: Fear\n",
    "- 5: Surprise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also important to note that the dataset is imbalanced, with the majority of samples belonging to the 'sadness' and 'joy' class. This imbalance will be important to understand the results of the finetuned model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    141067\n",
       "0    121187\n",
       "3     57317\n",
       "4     47712\n",
       "2     34554\n",
       "5     14972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary of categories\n",
    "categories = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "\n",
    "# Count the number of texts in each category, and convert the numerical value to a textual one\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us prepare a tokenizer, ready to be used with the BERT model. We will use the `distilbert-base-uncased` model, which is a smaller version of the BERT model, but which retains most of it's performance. This will allow us to train the model faster, and with less computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "foundation_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(foundation_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We also need to split the dataset into 'X' (features) and 'y' (target). We will also tokenize the text samples, and pad them to a fixed length of 512 tokens, which is the maximum length that the BERT model can handle. Notice how the tokenizer also adds special tokens to the input, such as the `[CLS]` token at the beginning of the input, and the `[SEP]` token at the end of the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416809, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] i just feel really helpless and heavy hearted [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X_tokenized = [tokenizer(text, max_length=512, padding='max_length', truncation=True)['input_ids'] for text in X]\n",
    "X_tokenized = np.array(X_tokenized)\n",
    "\n",
    "# Show the shape of X_tokenized\n",
    "print(X_tokenized.shape)\n",
    "\n",
    "# And the first element\n",
    "X_tokenized[0]\n",
    "\n",
    "# And the decoded text of the first element\n",
    "tokenizer.decode(X_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step before training the model, we will split the dataset into training and validation sets. We will use 80% of the data for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333447, 512)\n",
      "(83362, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets, we do not use a contant random state as we want to have different splits each time we run the code\n",
    "\n",
    "X_tokenized_train, X_tokenized_test, y_train, y_test = train_test_split(X_tokenized, y, test_size=0.2)\n",
    "\n",
    "print(X_tokenized_train.shape)\n",
    "print(X_tokenized_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model\n",
    "\n",
    "We will use the `TFDistilBertForSequenceClassification` class from the Transformers library to create a model for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 16:33:52.952624: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-04-20 16:33:52.952656: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2024-04-20 16:33:52.952670: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "2024-04-20 16:33:52.952700: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-20 16:33:52.952724: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "# Configure the model, there are a number of things we will leave untouched. \n",
    "model_config = DistilBertConfig.from_pretrained(foundation_model_name, num_labels=n_categories)\n",
    "\n",
    "#model = TFBertForSequenceClassification.from_pretrained(foundation_model_name, config=model_config)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(foundation_model_name, config=model_config)\n",
    "\n",
    "# Print the model configuration\n",
    "print(model.config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a brief overview of the model configuration above:\n",
    "\n",
    "- `dim` (Dimensionality of the Encoder Layers and Pooler Layer)\n",
    "\n",
    "    Value: 768\n",
    "\n",
    "    This parameter represents the size of the hidden layers, i.e., the dimensionality of the output vectors (embeddings) for each token in the input sequence. A dim of 768 means that every token processed by DistilBERT is converted into a vector with 768 elements. This is a standard dimension for smaller models like BERT-base, providing a good balance between computational efficiency and capacity to capture useful information in embeddings.\n",
    "\n",
    "- `hidden_dim` (Dimensionality of the Feed-Forward Layers within the Transformer)\n",
    "\n",
    "    Value: 3072\n",
    "\n",
    "    This parameter specifies the size of the feed-forward layers within each attention block of the model. The hidden_dim being 3072 means that these layers expand the 768-dimensional input embeddings to 3072 dimensions internally within the layer. This expansion allows the network to create and manipulate more complex features and relationships before projecting them back down to 768 dimensions to pass to the next layer.\n",
    "\n",
    "- `dropout` (Dropout Rate for Embeddings and Fully Connected Layers)\n",
    "\n",
    "    Value: 0.1\n",
    "\n",
    "    This parameter controls the dropout rate used on the output of each layer, before it is passed to the next layer. A dropout rate of 0.1 means that each element of the output vector from each layer (including the embeddings and the outputs of the hidden layers) has a 10% chance of being set to zero during training. This is a regularization technique used to prevent overfitting by reducing reliance on any single element within the feature vectors.\n",
    "\n",
    "- `attention_dropout` (Dropout Rate within Attention Mechanisms)\n",
    "\n",
    "    Value: 0.1\n",
    "\n",
    "    This parameter specifically controls the dropout rate for the attention scores in the attention mechanisms of the model. The attention_dropout of 0.1 implies that each attention score calculated (which determines how much each token should attend to every other token) has a 10% chance of being set to zero. This helps in making the attention mechanism robust, further helping to mitigate overfitting by ensuring that the model does not rely too heavily on specific parts of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model output\n",
    "\n",
    "The model outputs a tuple containing the loss and the logits. The loss is used to train the model, while the logits are the raw output of the model, before the activation function is applied. The logits can be converted to probabilities by applying the softmax function.\n",
    "\n",
    "```{note}\n",
    "In classification models, 'logits' refer to the raw output values produced by the final layer of a neural network before passing through a softmax activation function or any other normalization method that converts them into probabilities. The term \"logit\" typically stems from logistic regression in statistics, where it refers to the log-odds of a probability; that is, the logarithm of the odds\n",
    "\n",
    "$$\n",
    "\\text{Log-Odds} = \\log\\left(\\frac{p}{1-p}\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{p}$ is the probability of a positive outcome. In the context of neural networks, logits preserve this idea of being indirectly related to probabilities (pre-transformation values).\n",
    "\n",
    "In neural networks:\n",
    "\n",
    "- The logits are the outputs of the last linear transformation (using weights and biases), applied to the input of the final layer (e.g., the output of all previous layers in a neural network).\n",
    "- Mathematically, if $\\mathbf{z}$ represents the input vector to the final layer and $\\mathbf{W}$ and $\\mathbf{b}$ are the weight matrix and bias vector of that layer, respectively, then the logits $\\mathbf{l}$ are computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{l} = z \\cdot W + b\n",
    "$$\n",
    "\n",
    "\n",
    "The logits serve several key purposes:\n",
    "\n",
    "- Pre-Activation Values: They are considered pre-activation because they are often subject to further transformations depending on the specific task (e.g., passing through a softmax function for classification tasks).\n",
    "- Basis for Probabilities: For classification tasks, the logits are transformed by the softmax function to derive probabilities. The softmax function is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Softmax}(\\mathbf{l})_i = \\frac{e^{l_i}}{\\sum_k e^{l_k}}\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\mathbf{e}$ is the exponential function, $\\mathbf{l}_i$ is the $\\mathbf{i}th$ logit, and the denominator is the sum of exponential values of all logits. This transformation maps the logits onto the $\\mathbf{(0,1)}$ interval, and they sum to 1, forming a valid probability distribution.\n",
    "\n",
    "- Interpretability: Before applying softmax, logits can be any real number (positive, negative, zero), which makes them less interpretable in terms of probabilities. However, their relative values are informative; a higher logit value for one class compared to another indicates a stronger preference for that class before normalization.\n",
    "- Training Stability and Performance: Working with logits directly (especially in the loss functions such as cross-entropy) often leads to more numerically stable algorithms. This is because manipulating probabilities (which can approach zero and cause computational issues due to underflow) is prone to numerical errors.\n",
    "```\n",
    "\n",
    "Let's illustrate this with an example. We will use the first sample from the validation set to get the model's prediction. We will first get the logits, and then convert them to probabilities using the softmax function. The class with the highest probability will be the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "tf.Tensor([-0.07894903  0.0279115   0.07037467 -0.04731032 -0.05811661 -0.05221566], shape=(6,), dtype=float32)\n",
      "tf.Tensor([0.15737827 0.17512725 0.18272385 0.16243713 0.16069123 0.16164225], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample = X_tokenized_train[0]\n",
    "result = model(sample)\n",
    "\n",
    "# Print the shape of the logits\n",
    "print(result.logits.shape)\n",
    "\n",
    "# Print the first element of the logits (this is a tensor with 6 elements)\n",
    "print(result.logits[0])\n",
    "\n",
    "# Print the probabilities of the first element\n",
    "print(tf.nn.softmax(result.logits[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting the model\n",
    "\n",
    "We are now ready to compile and fit the model. We will use the Adam optimizer with a learning rate of $8 \\times 10^{-5}$, and the sparse categorical cross-entropy loss function. We will train the model for five epochs, and use the validation set to monitor the model's performance. Note the number of parameters in the model - even though we are using a smaller version of BERT, the model still has over 66 million adjustable parameters. We will also set a checkpoint callback to save the best model weights during training, this will be a long running process, so saving checkpoints means we can stop the training and resume it later without losing knowledge acquired by the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  4614      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66958086 (255.42 MB)\n",
      "Trainable params: 66958086 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "checkpoint_path = '.data/bert-emotions.keras'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    save_freq=batch_size, # Save after every batch\n",
    "    mode='max', # Save the model that maximizes the monitored quantity\n",
    "    monitor='accuracy')\n",
    "\n",
    "# Now let us train the model, we are going for a faster learning rate than the usual 5e-5 for BERT models\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=8e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "]\n",
    "model.compile(optimizer = optimizer, loss=loss, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check for any available checkpoints before starting the training process. If there are any, we will load the latest checkpoint and resume training from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint weights, continuing training...\n"
     ]
    }
   ],
   "source": [
    "# Load the latest checkpoint weights, if available\n",
    "try:\n",
    "    model.load_weights(checkpoint_path)\n",
    "    print(\"Loaded checkpoint weights, continuing training...\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load checkpoint weights, starting anew: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the training, let's take a look at some of the predictions made by the model on the validation set. We will use the model to predict the classes of five random samples in the validation set, and compare the predictions with the actual labels.\n",
    "\n",
    "BERT tokenizers play a crucial role in preparing text data for processing by the BERT model by converting text into a format that the model can understand. A critical part of this process involves the use of special tokens that help the model interpret the structure and meaning of the input data. Here’s a breakdown of these special tokens set by BERT tokenizers:\n",
    "\n",
    "```{note}\n",
    "- [CLS] Token\n",
    "\n",
    "Purpose: This token stands for \"classification\" and is used at the beginning of every text input. This is crucial for tasks that require a single output from the model, such as sentiment analysis or other classification tasks. The [CLS] token's final hidden state (i.e., the output of the transformer associated with this token) is used as the aggregate sequence representation for classification tasks.\n",
    "\n",
    "Usage Example: If your input is \"Hello, world!\", then the processed input starts with [CLS]: [CLS] Hello, world!.\n",
    "- [SEP] Token\n",
    "\n",
    "Purpose: The \"separator\" token is used to separate distinct segments of text inputs. It can also mark the end of a single sentence or the text sequence. In tasks involving multiple inputs (e.g., question answering formats that involve a question and a passage), [SEP] is used to separate the two different pieces.\n",
    "\n",
    "Usage Example: In a question answering setup where the question is \"What is your name?\" and the passage is \"My name is Sarah.\", the input would appear as: [CLS] What is your name? [SEP] My name is Sarah. [SEP]\n",
    "- [PAD] Token\n",
    "Purpose: Padding tokens are used to ensure that all sequences in a batch of text inputs are of the same length. Models generally require inputs to be of consistent size and shape, and padding allows shorter inputs to be extended to the required fixed length.\n",
    "\n",
    "Usage Example: For batching purposes, if the maximum sequence length is set to 10, and our input sequence is [CLS] Hi [SEP], which has only 3 tokens, it will be padded as: [CLS] Hi [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD].\n",
    "\n",
    "\n",
    "- [MASK] Token\n",
    "Purpose: Used predominantly in the training of BERT for masked language modeling. The [MASK] token replaces some percentage of the input tokens at random; then, the model learns to predict the original value of the masked tokens, based solely on the context provided by the other, non-masked, tokens. This process is fundamental to BERT’s bidirectional training approach.\n",
    "\n",
    "Usage Example: If we take the sentence \"I enjoy watching football\", and \"watching\" is chosen to be masked, the input would look like: [CLS] I enjoy [MASK] football [SEP]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  [CLS] i honestly feel that calling violent crime our farms are experiencing an organized racially motivated genocide campaign to be a pseudo issue obstructing many of us from understanding and dealing with the real cause of rural homicides [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Predicted category:  fear\n",
      "Actual category:  anger\n",
      "\n",
      "Text:  [CLS] i don t know but this feels kind of strange to me like it s going back to her debut days [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Predicted category:  surprise\n",
      "Actual category:  fear\n",
      "\n",
      "Text:  [CLS] i promptly went to bed proud as punch but feeling lousy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Predicted category:  sadness\n",
      "Actual category:  sadness\n",
      "\n",
      "Text:  [CLS] i have to organize and do a bunch of work for my dad to come and steal the show or make me feel unimportant [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Predicted category:  sadness\n",
      "Actual category:  sadness\n",
      "\n",
      "Text:  [CLS] i feel less ugly but when i look into the mirror i know i look like shit [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Predicted category:  sadness\n",
      "Actual category:  sadness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 5 elements from X_tokenized_train without replacement\n",
    "random_indexes = np.random.choice(len(X_tokenized_test), size=5, replace=False)\n",
    "random_sample = X_tokenized_test[random_indexes]\n",
    "result = model(random_sample)\n",
    "\n",
    "# Show the original text, the predicted category and the actual category\n",
    "for i, index in enumerate(random_indexes):\n",
    "    print(\"Text: \", tokenizer.decode(X_tokenized_test[index]))\n",
    "    print(\"Predicted category: \", categories[np.argmax(result.logits[i])])\n",
    "    print(\"Actual category: \", categories[y_test.iloc[index]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us train the model and evaluate it's performance. We will use the validation set to evaluate the model's performance, and we will set an early stopping callback to stop the training process if the validation loss does not improve for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32/10421 [..............................] - ETA: 13:14:14 - loss: 0.1553 - accuracy: 0.9189"
     ]
    }
   ],
   "source": [
    "# Run the training\n",
    "\n",
    "# Add a callback to stop the training when the validation loss does not improve\n",
    "stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_tokenized_train,\n",
    "    y_train,\n",
    "    validation_data=(X_tokenized_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint_callback, stop_callback])\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('.data/bert-emotions.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating performance\n",
    "\n",
    "We can evaluate the model's performance by plotting a confusion matrix of the predictions on the validation set as training progresses (we are checkpointing progress, so we can stop and restart training at will). This will help us understand how well the model is performing on each class. We will also calculate the classification report, which will give us a summary of the model's performance on each class, including metrics like precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606/2606 [==============================] - 3030s 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Get the probabilities of the categories\n",
    "\n",
    "# Assuming your model has been trained and you have your test set ready\n",
    "# Predict the probabilities on the test set\n",
    "probabilities = model.predict(X_tokenized_test)\n",
    "\n",
    "# Extract logits from the model's output\n",
    "logits = probabilities.logits\n",
    "\n",
    "# Apply softmax to logits to get probabilities\n",
    "probabilities = softmax(logits, axis=1)\n",
    "\n",
    "# Convert probabilities to predicted classes\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Define a custom colormap\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "    name='red_green_map', \n",
    "    colors=['red', 'yellow', 'green']\n",
    ")\n",
    "\n",
    "# Normalize the colormap to ensure that the diagonal (correct predictions) is green\n",
    "norm = mcolors.TwoSlopeNorm(vmin=0, vcenter=np.mean(cm), vmax=np.max(cm))\n",
    "\n",
    "# Plot the confusion matrix using Seaborn with the custom colormap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, norm=norm)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us also print the classification report, which will give us a summary of the model's performance on each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.78      1.00      0.87     24368\n",
      "         joy       0.94      0.91      0.92     28023\n",
      "        love       0.88      0.75      0.81      6962\n",
      "       anger       0.95      0.64      0.77     11539\n",
      "        fear       0.99      0.74      0.85      9522\n",
      "    surprise       0.72      0.97      0.82      2948\n",
      "\n",
      "    accuracy                           0.87     83362\n",
      "   macro avg       0.88      0.83      0.84     83362\n",
      "weighted avg       0.88      0.87      0.86     83362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report evaluates the performance of a model across multiple classes (in our case sadness, joy, love, anger, fear, surprise). Each class's performance is assessed using precision, recall, and the F1-score alongside the number of samples (support) for each class.\n",
    "\n",
    "Starting with **precision**, which indicates the accuracy of positive predictions for each emotion, the model performs best at predicting fear with a precision of 0.99, suggesting that nearly all predictions made by the model for fear are correct. Anger and joy also have high precision scores (0.95 and 0.94, respectively), meaning the model is reliable when it predicts these emotions. In contrast, surprise has the lowest precision at 0.72, indicating a higher rate of false positives for this class - this is to be expected, as it is the class which shows less often in the dataset.\n",
    "\n",
    "**Recall**, or the ability of the model to find all relevant cases within a dataset, is perfect for sadness at 1.00, meaning the model identifies all instances of sadness in the dataset. Surprise and joy also have high recall rates (0.97 and 0.91, respectively), showing that the model is capable of detecting most instances of these emotions. Anger has the lowest recall at 0.64.\n",
    "\n",
    "The **F1-score** provides a balance between precision and recall, taking into account both false positives and false negatives. Joy scores the highest with an F1-score of 0.92, indicative of a well-balanced precision and recall. Sadness and fear follow with F1-scores of 0.87 and 0.85, respectively. Anger, despite its high precision, has a lower F1-score of 0.77 due to its poor recall rate.\n",
    "\n",
    "The **support** column shows the number of actual occurrences of each class in the dataset, which informs us about the imbalance in the dataset's composition. Joy has the highest number of samples at 28,023, followed by sadness at 24,368, which might explain the model's effectiveness at identifying these emotions due to more extensive training data.\n",
    "\n",
    "Overall, the model achieves an **accuracy** of 0.87 across all predictions, which is quite high. The macro average for precision, recall, and F1-score are 0.88, 0.83, and 0.84 respectively, indicating good general performance across all classes. The weighted average, which accounts for the support of each class, shows similar performance with values of 0.88 for precision and 0.86 for F1-score, suggesting consistent performance weighted by the prevalence of each emotion in the dataset. This report highlights strengths in identifying sadness, joy, and fear effectively while pointing out weaknesses in detecting all instances of anger accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "In this experiment, we fine-tuned a pre-trained BERT model for text classification using the TensorFlow and Transformers libraries. We used the Emotion Dataset from the Hugging Face datasets library, which contains text samples labeled with one of six emotions: sadness, joy, love, anger, fear, and surprise. We used the `distilbert-base-uncased` model to create a text classification model and trained it on the dataset. We evaluated the model's performance using the validation set and calculated metrics like precision, recall, and F1-score for each class. The model achieved an accuracy of 0.87 and showed strengths in identifying sadness, joy, and fear effectively. The classification report provided a detailed summary of the model's performance on each class, highlighting areas of strength and areas for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "myst": {
    "html_meta": {
        "description": "This notebook demonstrates how to fine-tune a pre-trained BERT model for text classification using the TensorFlow and Transformers libraries. We use the Emotion Dataset from the Hugging Face datasets library, which contains text samples labeled with one of six emotions: sadness, joy, love, anger, fear, and surprise. We use the `distilbert-base-uncased` model to create a text classification model and train it on the dataset. We evaluate the model's performance using the validation set and calculate metrics like precision, recall, and F1-score for each class.",
        "keywords": "Machine Learning, Natural Language Processing, BERT, Text Classification, Emotion Recognition, TensorFlow, Transformers, Hugging Face, Classification Report, Confusion Matrix, Pedro, Pedro Leitao"
    }
}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
