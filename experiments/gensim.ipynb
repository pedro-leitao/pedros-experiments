{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vectors are a mainstay of NLP, and are used in a variety of tasks, from sentiment analysis to machine translation. In this experiment, we will explore the very basics of word vectors, and how they can be used to represent words in a way that captures their meaning. Word vector models represent words as vectors in a high-dimensional space, where the distance between vectors captures the similarity and relationships between words within a given context of a corpus.\n",
    "\n",
    "For the purposes of simplicity, we will use the `gensim` library and a ready made word vector model. The model we will use is the `glove-wiki-gigaword-50` model, which is a 50-dimensional word vector model trained on the Wikipedia corpus.\n",
    "\n",
    "Let's start by loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word vectors for question answering\n",
    "\n",
    "We will use this model to explore the relationships between words. Let us start with a simple problem - \"Brasil is to Portugal, what _X_ is to Spain\". We will use word vectors to estimate possible candidates to _X_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the \"br - pt + es\" vector and find the closest word\n",
    "result = model.most_similar(positive=['brazil', 'spain'], negative=['portugal'], topn=1)\n",
    "print(result)\n",
    "result_word = result[0][0]\n",
    "# Print the shape of the result vector\n",
    "dimensions = model[result[0][0]].shape[0]\n",
    "print(\"Number of vector dimensions: \", dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have a candidate word for _X_ and a probability score, also notice how the resulting word vector returned by the model has 50 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model[result[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers encode a lot of meaning regarding the word 'mexico', and in general, the more dimensions present in a given word vector model the more semantic information can be represented by the model!\n",
    "\n",
    "## Visualising word vectors\n",
    "\n",
    "Now let us attempt to visualise the relationships between these vector representations - we will perform a comparison between an actual vector operation, and the estimate returned by `gensim` using the `most_similar` operation. We first need to get vector representations for all the words (\"portugal\", \"brazil\", \"spain\" and \"mexico\") so we can plot their proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the \"brazil + spain - portugal\" vector\n",
    "true_vector = model['brazil'] + model['spain'] - model['portugal']\n",
    "\n",
    "words = ['portugal', 'spain', 'brazil', result_word]\n",
    "\n",
    "# Get vectors for each word\n",
    "vectors = np.array([model[w] for w in words])\n",
    "vectors = np.vstack([vectors, true_vector])  # Add the true vector to the list of vectors\n",
    "words += ['brazil + spain - portugal']  # Add the label for the true vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how do we visualize 50 dimensions? We'll need to reduce the dimensionality of our vector space to something manageable! \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note: </b>\n",
    "In this case, we will use Principal Component Analysis (PCA), a statistical procedure that utilizes orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. A better approach would be using t-SNE, but given we have a tiny number of samples, it makes little or no difference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Perform PCA to reduce to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "reduced_vectors = pca.fit_transform(vectors)\n",
    "\n",
    "# Generate a color map similar to matplotlib's tab10\n",
    "colors = [f'rgba({r},{g},{b},{a})' for r, g, b, a in plt.cm.tab10(np.linspace(0, 1, len(words)))]\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot\n",
    "fig.add_trace(go.Scatter3d(x=reduced_vectors[:, 0], y=reduced_vectors[:, 1], z=reduced_vectors[:, 2],\n",
    "                           mode='markers+text', text=words, marker=dict(color=colors), textposition=\"top center\"))\n",
    "\n",
    "# Optionally add lines from origin to each point if you need to mimic the quiver plot\n",
    "# This is a bit more involved in Plotly, as you'll have to add a line for each point manually\n",
    "for i, word in enumerate(words):\n",
    "    linestyle = 'dash' if word == 'mexico' else 'solid'\n",
    "    fig.add_trace(go.Scatter3d(x=[0, reduced_vectors[i, 0]], y=[0, reduced_vectors[i, 1]], z=[0, reduced_vectors[i, 2]],\n",
    "                               mode='lines', line=dict(color=colors[i], dash=linestyle)))\n",
    "\n",
    "# Set titles and labels\n",
    "fig.update_layout(scene=dict(xaxis_title='X Axis', yaxis_title='Y Axis', zaxis_title='Z Axis'),\n",
    "                  legend_title=\"Words\", title=\"3D PCA projection of Word Vectors\", height=600)\n",
    "\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the \"true\" vector (the red line) doesn't seem to align much or be anywhere near \"mexico\" ? This can simply be explained by dimensionality reduction - the original number of dimensions is much higher than three, and our dimenionality reduction does not capture the complexity of the data. Take the above as a mere ilustration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to offer a different visualisation, let us perform an interactive 3D plot of a variety of countries using Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "countries = ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burundi', 'cambodia', 'cameroon', 'canada', 'chad', 'chile', 'china', 'colombia', 'comoros', 'croatia', 'cuba', 'cyprus', 'denmark', 'djibouti', 'dominica', 'ecuador', 'egypt', 'eritrea', 'estonia', 'ethiopia', 'fiji', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'grenada', 'guatemala', 'guinea', 'guinea-bissau', 'guyana', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kiribati', 'kuwait', 'kyrgyzstan', 'laos', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'mauritania', 'mauritius', 'mexico', 'micronesia', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nauru', 'nepal', 'netherlands', 'nicaragua', 'niger', 'nigeria', 'norway', 'oman', 'pakistan', 'palau', 'panama', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'samoa', 'senegal', 'serbia', 'seychelles', 'singapore', 'slovakia', 'slovenia', 'somalia', 'spain', 'sudan', 'suriname', 'sweden', 'switzerland', 'syria', 'tajikistan', 'tanzania', 'thailand', 'timor-leste', 'togo', 'tonga', 'tunisia', 'turkey', 'turkmenistan', 'tuvalu', 'uganda', 'ukraine', 'uruguay', 'uzbekistan', 'vanuatu', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe']\n",
    "\n",
    "vectors = np.array([model[country] for country in countries])\n",
    "\n",
    "# Perform t-SNE to reduce to 3 dimensions\n",
    "tsne = TSNE(n_components=3, random_state=42)  # Setting a random_state for reproducibility\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plotting the 3D projection\n",
    "\n",
    "xs = reduced_vectors[:,0]\n",
    "ys = reduced_vectors[:,1]\n",
    "zs = reduced_vectors[:,2]\n",
    "\n",
    "# Create a 3D scatter plot using Plotly\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=xs,\n",
    "    y=ys,\n",
    "    z=zs,\n",
    "    text=countries,  # Use country names as hover text\n",
    "    mode='markers+text',  # Combine markers and text\n",
    "    marker=dict(\n",
    "        size=5,  # Marker size\n",
    "        color=zs,  # Color markers by their z-values for depth effect\n",
    "        colorscale='Viridis',  # Choose a color scale\n",
    "        opacity=0.8  # Marker opacity\n",
    "    ),\n",
    "    textposition='top center'  # Position the text above the markers\n",
    ")])\n",
    "\n",
    "# Update layout for a cleaner look\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis'\n",
    "    ),\n",
    "    title=\"3D t-SNE Projection of Country Word Vectors\",\n",
    "    legend_title=\"Countries\",\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering further questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us investigate a few more questions to see what the model returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codfish is to Portugal as ? is to Spain\n",
    "result = model.most_similar(positive=['spain', 'codfish'], negative=['portugal'], topn=1)\n",
    "print(result)\n",
    "\n",
    "# Barcelona is to Spain as ? is to Portugal\n",
    "result = model.most_similar(positive=['portugal', 'barcelona'], negative=['spain'], topn=1)\n",
    "print(result)\n",
    "\n",
    "# Lisbon is to Portugal as ? is to Britain\n",
    "result = model.most_similar(positive=['britain', 'lisbon'], negative=['portugal'], topn=1)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
